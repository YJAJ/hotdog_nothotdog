{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotdog vs Not hotdog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to develop a model that distinguishes hotdogs from not hotdogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'D:\\\\ML\\\\fastai\\\\Projects\\\\hotdog_nothotdog'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create reference to important directories\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "HOTDOG_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#Get relative imports to directories above hotdog_nothotdog/\n",
    "#sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "#Import utils\n",
    "from utils import *\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "import json\n",
    "#glob for finding all the pathnames matching a specified pattern according to the rules used by the Unix shell\n",
    "from glob import glob\n",
    "#numpy import\n",
    "import numpy as np\n",
    "#scipy import\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numpy modules and scipy modules import\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "#keras import\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#bcolz for saving arrays\n",
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_array(fname, arr):\n",
    "    c = bcolz.carray(arr, rootdir = fname, mode = 'w');\n",
    "    c.flush()\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create sample sets and set data directories\n",
    "2. Train the original vgg16 model\n",
    "3. Modify the original model and retrain the last layer\n",
    "4. Drop out\n",
    "5. Data augmentation\n",
    "6. Batch normalisation\n",
    "7. Generate predictions\n",
    "8. Validate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample sets and data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\fastai\\Projects\\hotdog_nothotdog\\data\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "path = DATA_HOME_DIR + '/'\n",
    "#path = DATA_HOME_DIR + '/sample/'\n",
    "sample_path = DATA_HOME_DIR + '/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/'\n",
    "results_path = DATA_HOME_DIR + '/results/'\n",
    "train_path = path + '/train/'\n",
    "valid_path = path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run bash below to move original images from other directories to train directories\n",
    "#$ find D:/ML/fastai/Projects/hotdog_nothotdog/data/food-101/images/all/ -type f | shuf -n 1800 | xargs -I file \n",
    "#mv file 'D:\\ML\\fastai\\Projects\\hotdog_nothotdog\\data\\train\\nothotdog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\fastai\\Projects\\hotdog_nothotdog\\data\\train\\hotdog\n"
     ]
    }
   ],
   "source": [
    "#%cd $DATA_HOME_DIR/train/hotdog\n",
    "\n",
    "#g = glob('*.jpg')\n",
    "#shuf = np.random.permutation(g)\n",
    "#for i in range(250):\n",
    "#    os.rename(shuf[i], DATA_HOME_DIR+'/test/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\fastai\\Projects\\hotdog_nothotdog\\data\\train\\hotdog\n"
     ]
    }
   ],
   "source": [
    "#%cd $train_path/hotdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#g = glob('*.jpg')\n",
    "#shuf = np.random.permutation(g)\n",
    "#for i in range(500):\n",
    "#    os.rename(shuf[i], DATA_HOME_DIR+'/valid/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#g = glob('*.jpg')\n",
    "#shuf = np.random.permutation(g)\n",
    "#for i in range(200):\n",
    "#    copyfile(shuf[i], sample_path+'/train/hotdog/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\fastai\\Projects\\hotdog_nothotdog\\data\\valid\\hotdog\n"
     ]
    }
   ],
   "source": [
    "#%cd $valid_path/hotdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#g = glob('*.jpg')\n",
    "#shuf = np.random.permutation(g)\n",
    "#for i in range(100):\n",
    "#    copyfile(shuf[i], sample_path+'/valid/hotdog/'+shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the original vgg16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set batch size and number of epoch\n",
    "batch_size = 32\n",
    "no_of_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5100 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Finetune\n",
    "batches = vgg.get_batches(train_path, batch_size = batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size = batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "\n",
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5100 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_data = get_data(path+'train')\n",
    "val_data = get_data(path+'valid')\n",
    "\n",
    "trn_classes = batches.classes\n",
    "val_classes = val_batches.classes\n",
    "trn_labels = onehot(trn_classes)\n",
    "val_labels = onehot(val_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100L, 3L, 224L, 224L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000L, 3L, 224L, 224L)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "5100/5100 [==============================] - 1598s - loss: 1.1077 - acc: 0.8980 - val_loss: 1.0418 - val_acc: 0.9160\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "5100/5100 [==============================] - 1571s - loss: 1.1346 - acc: 0.9120 - val_loss: 1.1486 - val_acc: 0.9190\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "5100/5100 [==============================] - 1589s - loss: 1.0508 - acc: 0.9229 - val_loss: 0.8046 - val_acc: 0.9400\n",
      "Running epoch: 3\n",
      "Epoch 1/1\n",
      "5100/5100 [==============================] - 1598s - loss: 1.1807 - acc: 0.9127 - val_loss: 0.9451 - val_acc: 0.9310\n",
      "Running epoch: 4\n",
      "Epoch 1/1\n",
      "5100/5100 [==============================] - 1592s - loss: 1.0826 - acc: 0.9229 - val_loss: 1.0669 - val_acc: 0.9250\n",
      "Completed 5 fit operations\n"
     ]
    }
   ],
   "source": [
    "#Save weights\n",
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print (\"Running epoch: %d\" % epoch)\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d5.h5' % epoch\n",
    "    model.save_weights(results_path+latest_weights_filename)\n",
    "print (\"Completed %s fit operations\" % no_of_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the original model and retrain the revised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 3, 224, 224)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_14 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_15 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_16 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_17 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_18 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_19 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_20 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_21 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_22 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_23 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_24 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_25 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_26 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 512, 7, 7)     0           convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25088)         0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4096)          102764544   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          16781312    dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4096)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 2)             8194        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "for layer in model.layers: layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 3, 224, 224)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_14 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_15 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_16 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_17 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_18 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_19 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_20 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_21 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_22 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_23 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_24 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_25 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_26 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 512, 7, 7)     0           convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25088)         0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4096)          102764544   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          16781312    dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4096)          0           dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 0\n",
      "Non-trainable params: 134,260,544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(trn_data, trn_labels, batch_size = batch_size, shuffle = True)\n",
    "val_batches = gen.flow(val_data, val_labels, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, batches, val_batches, nb_epoch = 1):\n",
    "    model.fit_generator(batches, samples_per_epoch=batches.n, nb_epoch = nb_epoch,\n",
    "                       validation_data=val_batches, nb_val_samples= val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt=RMSprop(lr=0.1)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 3, 224, 224)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_14 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_15 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_16 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_17 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_18 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_19 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_20 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_21 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_22 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_23 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_24 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_25 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_26 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 512, 7, 7)     0           convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25088)         0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4096)          102764544   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          16781312    dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4096)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 2)             8194        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5100/5100 [==============================] - 1581s - loss: 4.0237 - acc: 0.7441 - val_loss: 1.4144 - val_acc: 0.9100\n",
      "Epoch 2/5\n",
      "5100/5100 [==============================] - 1582s - loss: 2.0084 - acc: 0.8733 - val_loss: 1.3130 - val_acc: 0.9170\n",
      "Epoch 3/5\n",
      "5100/5100 [==============================] - 1581s - loss: 1.7034 - acc: 0.8924 - val_loss: 2.7496 - val_acc: 0.8260\n",
      "Epoch 4/5\n",
      "5100/5100 [==============================] - 1581s - loss: 1.5676 - acc: 0.9012 - val_loss: 1.3374 - val_acc: 0.9140\n",
      "Epoch 5/5\n",
      "5100/5100 [==============================] - 1580s - loss: 1.4348 - acc: 0.9098 - val_loss: 1.5756 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, batches, val_batches, nb_epoch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up path for model_path\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_path+'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 264s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5756402702331576, 0.90000000000000002]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 265s   \n",
      "1000/1000 [==============================] - 266s   \n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(val_data, batch_size = batch_size)\n",
    "probs = model.predict_proba(val_data, batch_size = batch_size) [:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_classes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[482  18]\n",
      " [ 82 418]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAEmCAYAAAA5jbhCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nq5lZzpxYzcxy5sRqZpaz/wdxz+vZBGQJ1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a0654a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, {'hotdog':0, 'nothotdog':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain all dense layers after retraining the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "#Index of the first dense layer\n",
    "first_dense_idx = [index for index, layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "#Set the first dense layer and subsequent layers trainable\n",
    "for layer in layers[first_dense_idx:]: layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5100/5100 [==============================] - 1595s - loss: 1.5774 - acc: 0.8992 - val_loss: 1.1837 - val_acc: 0.9240\n",
      "Epoch 2/5\n",
      "5100/5100 [==============================] - 1592s - loss: 1.3271 - acc: 0.9163 - val_loss: 1.3207 - val_acc: 0.9180\n",
      "Epoch 3/5\n",
      "5100/5100 [==============================] - 1582s - loss: 1.3368 - acc: 0.9155 - val_loss: 1.3010 - val_acc: 0.9170\n",
      "Epoch 4/5\n",
      "5100/5100 [==============================] - 1580s - loss: 1.3440 - acc: 0.9147 - val_loss: 1.1465 - val_acc: 0.9280\n",
      "Epoch 5/5\n",
      "5100/5100 [==============================] - 1579s - loss: 1.2667 - acc: 0.9194 - val_loss: 1.3539 - val_acc: 0.9160\n"
     ]
    }
   ],
   "source": [
    "K.set_value(opt.lr, 0.01)\n",
    "fit_model(model, batches, val_batches, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'finetune2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the model is underfitting (accuracy of training set < accuracy of validation set). I will make dropout rates to zero so that I can check whether the model is underfitting due to inappropriate dropout rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the working model\n",
    "vgg = vgg_ft(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reload the previous weights that were retrained in all dense layers\n",
    "model.load_weights(model_path+'finetune2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "#Index of the last convolutional layer\n",
    "last_conv_idx = [index for index, layer in enumerate(layers) if type(layer) is Convolution2D][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Convolution2D at 0xe953b70>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[last_conv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make the model for convolutional layers so that we use the model as it is\n",
    "conv_layers = layers[:last_conv_idx+1]\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make the model for dense (fully connected) layers\n",
    "fc_layers = layers[last_conv_idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5100 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(train_path, shuffle = False, batch_size = batch_size)\n",
    "val_batches = get_batches(valid_path, shuffle = False, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hotdog': 0, 'nothotdog': 1}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = conv_model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path+'train_convlayer_features.bc', trn_features)\n",
    "save_array(model_path+'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(model_path+'train_convlayer_features.bc')\n",
    "val_features = load_array(model_path+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100L, 512L, 14L, 14L)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copy the weights from the pre-trained model\n",
    "def proc_wgts(layer):\n",
    "    return [o for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.00001, rho=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(2, activation='softmax')\n",
    "        ])\n",
    "    for l1, l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "        \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "maxpooling2d_16 (MaxPooling2D)   (None, 512, 7, 7)     0           maxpooling2d_input_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 25088)         0           maxpooling2d_16[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 4096)          102764544   flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 4096)          0           dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 4096)          16781312    dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 4096)          0           dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 2)             8194        dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 119,554,050\n",
      "Trainable params: 119,554,050\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5100 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "5100/5100 [==============================] - 209s - loss: 1.0853 - acc: 0.9314 - val_loss: 1.2432 - val_acc: 0.9210\n",
      "Epoch 2/8\n",
      "5100/5100 [==============================] - 261s - loss: 1.0258 - acc: 0.9353 - val_loss: 1.2240 - val_acc: 0.9240\n",
      "Epoch 3/8\n",
      "5100/5100 [==============================] - 406s - loss: 1.0781 - acc: 0.9322 - val_loss: 1.1597 - val_acc: 0.9280\n",
      "Epoch 4/8\n",
      "5100/5100 [==============================] - 519s - loss: 0.9781 - acc: 0.9376 - val_loss: 1.0025 - val_acc: 0.9370\n",
      "Epoch 5/8\n",
      "5100/5100 [==============================] - 522s - loss: 0.9920 - acc: 0.9375 - val_loss: 1.0590 - val_acc: 0.9330\n",
      "Epoch 6/8\n",
      "5100/5100 [==============================] - 562s - loss: 0.8527 - acc: 0.9461 - val_loss: 1.0784 - val_acc: 0.9320\n",
      "Epoch 7/8\n",
      "5100/5100 [==============================] - 627s - loss: 0.8152 - acc: 0.9486 - val_loss: 1.0992 - val_acc: 0.9300\n",
      "Epoch 8/8\n",
      "5100/5100 [==============================] - 605s - loss: 0.8691 - acc: 0.9453 - val_loss: 0.9971 - val_acc: 0.9370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231c6dd8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(trn_features, trn_labels, nb_epoch=8,batch_size=batch_size, \n",
    "             validation_data = (val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.save_weights(model_path+'no_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.load_weights(model_path+'no_dropout.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I made the dropout rates to zero, the model is overfitting at the moment. I will attempt to reduce overfitting through data augmentation and batch normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Through data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Through ImageDataGenerator, augment the data\n",
    "gen = image.ImageDataGenerator(rotation_range=5, width_shift_range=0.1,\n",
    "                              height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Then pass the augmented data into batches, we should not change valid set images\n",
    "batches = get_batches(path+'train', gen, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set conv_model not trainable\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "#Just add the fully connected layers to the conv_model\n",
    "conv_model.add(fc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "5100/5100 [==============================] - 1848s - loss: 1.3408 - acc: 0.9153 - val_loss: 1.2054 - val_acc: 0.9250\n",
      "Epoch 2/8\n",
      "5100/5100 [==============================] - 1889s - loss: 1.2721 - acc: 0.9200 - val_loss: 1.1942 - val_acc: 0.9250\n",
      "Epoch 3/8\n",
      "5100/5100 [==============================] - 2016s - loss: 1.1477 - acc: 0.9275 - val_loss: 1.1444 - val_acc: 0.9290\n",
      "Epoch 4/8\n",
      "5100/5100 [==============================] - 2116s - loss: 1.1882 - acc: 0.9249 - val_loss: 1.1189 - val_acc: 0.9270\n",
      "Epoch 5/8\n",
      "5100/5100 [==============================] - 2142s - loss: 1.0363 - acc: 0.9345 - val_loss: 1.2250 - val_acc: 0.9240\n",
      "Epoch 6/8\n",
      "5100/5100 [==============================] - 2195s - loss: 1.0779 - acc: 0.9320 - val_loss: 1.3073 - val_acc: 0.9180\n",
      "Epoch 7/8\n",
      "5100/5100 [==============================] - 2150s - loss: 1.0540 - acc: 0.9324 - val_loss: 1.1090 - val_acc: 0.9310\n",
      "Epoch 8/8\n",
      "5100/5100 [==============================] - 2177s - loss: 1.0810 - acc: 0.9320 - val_loss: 0.9515 - val_acc: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x37826128>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=8, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.save_weights(model_path+'aug1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.load_weights(model_path+'aug1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Through batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 3, 224, 224)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_14 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_14[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_15 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_14[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_15[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_15[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_16 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_6[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_16[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_17 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_16[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_17[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_17[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_18 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_7[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_18[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_19 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_18[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_19[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_20 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_19[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_20[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_20[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_21 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_8[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_21[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_22 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_21[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_22[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_23 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_22[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_23[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_23[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_24 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_9[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_24[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_25 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_24[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_25[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_26 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_25[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_26[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)        (None, 2)             119554050   convolution2d_26[1][0]           \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 119,554,050\n",
      "Non-trainable params: 14,714,688\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 14, 14)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(1000, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fc_weights_from_vgg16bn(model):\n",
    "    \"Load weights for model from the dense layers of the Vgg16BN model.\"\n",
    "    # See imagenet_batchnorm.ipynb for info on how the weights for\n",
    "    # Vgg16BN can be generated from the standard Vgg16 weights.\n",
    "    from vgg16bn import Vgg16BN\n",
    "    vgg16_bn = Vgg16BN()\n",
    "    _, fc_layers = split_at(vgg16_bn.model, Convolution2D)\n",
    "    copy_weights(fc_layers, model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_fc_weights_from_vgg16bn(bn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_wgts(layer, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in bn_model.layers: \n",
    "    if type(l)==Dense: l.set_weights(proc_wgts(l, 0.5, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.pop()\n",
    "for layer in bn_model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5100 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "5100/5100 [==============================] - 16s - loss: 0.8485 - acc: 0.8527 - val_loss: 0.3724 - val_acc: 0.9260\n",
      "Epoch 2/8\n",
      "5100/5100 [==============================] - 15s - loss: 0.6742 - acc: 0.8835 - val_loss: 0.3732 - val_acc: 0.9280\n",
      "Epoch 3/8\n",
      "5100/5100 [==============================] - 15s - loss: 0.6159 - acc: 0.8980 - val_loss: 0.3691 - val_acc: 0.9230\n",
      "Epoch 4/8\n",
      "5100/5100 [==============================] - 15s - loss: 0.6332 - acc: 0.8957 - val_loss: 0.3188 - val_acc: 0.9320\n",
      "Epoch 5/8\n",
      "5100/5100 [==============================] - 15s - loss: 0.6217 - acc: 0.8935 - val_loss: 0.3689 - val_acc: 0.9340\n",
      "Epoch 6/8\n",
      "5100/5100 [==============================] - 15s - loss: 0.6611 - acc: 0.8971 - val_loss: 0.4126 - val_acc: 0.9270\n",
      "Epoch 7/8\n",
      "5100/5100 [==============================] - 15s - loss: 0.6743 - acc: 0.8990 - val_loss: 0.3773 - val_acc: 0.9300\n",
      "Epoch 8/8\n",
      "5100/5100 [==============================] - 15s - loss: 0.6861 - acc: 0.8988 - val_loss: 0.4052 - val_acc: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x69c867f0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(trn_features, trn_labels, nb_epoch=8, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(model_path+'bn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(model_path+'bn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_layers = get_bn_layers(0.6)\n",
    "bn_layers.pop()\n",
    "bn_layers.append(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: layer.trainable = False\n",
    "for layer in bn_layers: final_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=Adam(), \n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5100/5100 [==============================] - 1974s - loss: 2.0078 - acc: 0.8557 - val_loss: 1.4511 - val_acc: 0.8980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6d728320>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "5100/5100 [==============================] - 1978s - loss: 1.3795 - acc: 0.8998 - val_loss: 1.3296 - val_acc: 0.9060\n",
      "Epoch 2/4\n",
      "5100/5100 [==============================] - 1896s - loss: 1.3037 - acc: 0.9067 - val_loss: 1.3930 - val_acc: 0.9040\n",
      "Epoch 3/4\n",
      "5100/5100 [==============================] - 1872s - loss: 1.1976 - acc: 0.9112 - val_loss: 1.1342 - val_acc: 0.9140\n",
      "Epoch 4/4\n",
      "5100/5100 [==============================] - 2234s - loss: 1.0886 - acc: 0.9176 - val_loss: 1.0054 - val_acc: 0.9230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6ffb1d68>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(model_path + 'final2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "5100/5100 [==============================] - 2221s - loss: 1.1054 - acc: 0.9163 - val_loss: 1.1947 - val_acc: 0.9110\n",
      "Epoch 2/4\n",
      "5100/5100 [==============================] - 2183s - loss: 0.9160 - acc: 0.9282 - val_loss: 1.1284 - val_acc: 0.9140\n",
      "Epoch 3/4\n",
      "5100/5100 [==============================] - 2200s - loss: 0.8180 - acc: 0.9312 - val_loss: 0.8611 - val_acc: 0.9270\n",
      "Epoch 4/4\n",
      "5100/5100 [==============================] - 2134s - loss: 0.8532 - acc: 0.9312 - val_loss: 0.8497 - val_acc: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x716d19e8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(model_path + 'final3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@inproceedings{bossard14,\n",
    "  title = {Food-101 -- Mining Discriminative Components with Random Forests},\n",
    "  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},\n",
    "  booktitle = {European Conference on Computer Vision},\n",
    "  year = {2014}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
